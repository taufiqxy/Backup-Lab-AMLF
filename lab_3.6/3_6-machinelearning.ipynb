{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.6 - Student Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This lab is a continuation of the guided labs in Module 3.\n",
    "\n",
    "In this lab, you will evaluate the model that you trained in previous modules. You will also calculate metrics based on the results of the test data.\n",
    "\n",
    "\n",
    "## Introduction to the business scenario\n",
    "\n",
    "You work for a healthcare provider, and want to improve the detection of abnormalities in orthopedic patients. \n",
    "\n",
    "You are tasked with solving this problem by using machine learning (ML). You have access to a dataset that contains six biomechanical features and a target of *normal* or *abnormal*. You can use this dataset to train an ML model to predict if a patient will have an abnormality.\n",
    "\n",
    "\n",
    "## About this dataset\n",
    "\n",
    "This biomedical dataset was built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre Médico-Chirurgical de Réadaptation des Massues, Lyon, France. The data has been organized in two different, but related, classification tasks. \n",
    "\n",
    "The first task consists in classifying patients as belonging to one of three categories: \n",
    "\n",
    "- *Normal* (100 patients)\n",
    "- *Disk Hernia* (60 patients)\n",
    "- *Spondylolisthesis* (150 patients)\n",
    "\n",
    "For the second task, the categories *Disk Hernia* and *Spondylolisthesis* were merged into a single category that is labeled as *abnormal*. Thus, the second task consists in classifying patients as belonging to one of two categories: *Normal* (100 patients) or *Abnormal* (210 patients).\n",
    "\n",
    "\n",
    "## Attribute information\n",
    "\n",
    "Each patient is represented in the dataset by six biomechanical attributes that are derived from the shape and orientation of the pelvis and lumbar spine (in this order): \n",
    "\n",
    "- Pelvic incidence\n",
    "- Pelvic tilt\n",
    "- Lumbar lordosis angle\n",
    "- Sacral slope\n",
    "- Pelvic radius\n",
    "- Grade of spondylolisthesis\n",
    "\n",
    "The following convention is used for the class labels: \n",
    "- DH (Disk Hernia)\n",
    "- Spondylolisthesis (SL)\n",
    "- Normal (NO) \n",
    "- Abnormal (AB)\n",
    "\n",
    "For more information about this dataset, see the [Vertebral Column dataset webpage](http://archive.ics.uci.edu/ml/datasets/Vertebral+Column).\n",
    "\n",
    "\n",
    "## Dataset attributions\n",
    "\n",
    "This dataset was obtained from:\n",
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository (http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab setup\n",
    "\n",
    "Because this solution is split across several labs in the module, you run the following cells so that you can load the data and train the model to be deployed.\n",
    "\n",
    "**Note:** The setup can take up to 5 minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data and training the model\n",
    "\n",
    "By running the following cells, the data will be imported and ready for use. \n",
    "\n",
    "**Note:** The following cells represent the key steps in the previous labs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c76966a1586022l3893503t1w057445642632-labbucket-ma386ifzln95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-04-07-05-06-28-727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-04-07 05:06:30 Starting - Starting the training job....\n",
      "2023-04-07 05:06:55 Starting - Preparing the instances for training...............\n",
      "2023-04-07 05:08:17 Downloading - Downloading input data.....\n",
      "2023-04-07 05:08:47 Training - Downloading the training image........\n",
      "2023-04-07 05:09:32 Training - Training image download completed. Training in progress....\n",
      "2023-04-07 05:09:53 Uploading - Uploading generated training model..\n",
      "2023-04-07 05:10:09 Completed - Training job completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2023-04-07-05-10-11-574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2023-04-07-05-10-12-281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................."
     ]
    }
   ],
   "source": [
    "f_zip = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip'\n",
    "r = requests.get(f_zip, stream=True)\n",
    "Vertebral_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "Vertebral_zip.extractall()\n",
    "\n",
    "data = arff.loadarff('column_2C_weka.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "class_mapper = {b'Abnormal':1,b'Normal':0}\n",
    "df['class']=df['class'].replace(class_mapper)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "train, test_and_validate = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5, random_state=42, stratify=test_and_validate['class'])\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_file='vertebral_train.csv'\n",
    "test_file='vertebral_test.csv'\n",
    "validate_file='vertebral_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"auc\",\n",
    "             \"objective\": \"binary:logistic\"}\n",
    "\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False)\n",
    "\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)\n",
    "\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait()\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),',',names=['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Exploring the results\n",
    "\n",
    "The output from the model will be a probablility. You must first convert that probability into one of the two classes, either *0* or *1*. To do this, you can create a function to perform the conversion. Note the use of the threshold in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_convert(x):\n",
    "    threshold = 0.3\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n",
    "\n",
    "print(target_predicted_binary.head(5))\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, you can see that the initial model might not be that good. It's difficult to tell by comparing a few values.\n",
    "\n",
    "Next, you will generate some metrics to see how well the model performs.\n",
    "\n",
    "\n",
    "# Step 2: Creating a confusion matrix\n",
    "\n",
    "A *confusion matrix* is one of the key ways of measuring a classification model's performance. It's a table that maps out the correct and incorrect predictions. After you calculate a confusion matrix for your model, you can generate several other statistics. However, you will start by only creating the confusion matrix.\n",
    "\n",
    "To create a confusion matrix, you need both the target values from your test data *and* the predicted value. \n",
    "\n",
    "Get the targets from the test DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test.iloc[:,0]\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the *scikit-learn* library, which contains a function to create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(test_labels, target_predicted_binary)\n",
    "df_confusion = pd.DataFrame(matrix, index=['Nnormal','Abnormal'],columns=['Normal','Abnormal'])\n",
    "\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You results will vary, but you should have results that are similiar to this example:\n",
    "\n",
    "_ | Normal | Abnormal\n",
    "---------- | ----: | ----:\n",
    "Normal | 7  | 3\n",
    "Abnormal | 3  | 18\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous table shows that the model correctly predicted *7 Normal* and *18 Abnormal* values. However, it incorrectly predicted *3 Normal* and *3 Abnormal* values. \n",
    "\n",
    "By using the *seaborn* and *matplotlib* Python libraries, you can plot these values in a chart to make them easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colormap = sns.color_palette(\"BrBG\", 10)\n",
    "sns.heatmap(df_confusion, annot=True, cbar=None, cmap=colormap)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** If the chart doesn't display the first time, try running the cell again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these results are good enough for your application, then the model might be good enough. However, because there are consequences from incorrectly predicting *Normal* values -- that is, no abnormality was found when there actually was one -- the focus should be on reducing this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculating performance statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to compare this model to the next model that you create, you need some metrics that you can record. For a binary classification problem, the confusion matrix data can be used to calculate various metrics.\n",
    "\n",
    "To start, extract the values from the confusion matrix cells into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()\n",
    "\n",
    "print(f\"True Negative (TN) : {TN}\")\n",
    "print(f\"False Positive (FP): {FP}\")\n",
    "print(f\"False Negative (FN): {FN}\")\n",
    "print(f\"True Positive (TP) : {TP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now calculate some statistics.\n",
    "\n",
    "\n",
    "### Sensitivity\n",
    "\n",
    "*Sensitivity* is also known as *hit rate*, *recall*, or *true positive rate (TPR)*. It measures the proportion of the actual positives that are correctly identified.\n",
    "\n",
    "In this example, the sensitivity is *the probablity of detecting an abnormality for patients with an abnormality*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "Sensitivity  = float(TP)/(TP+FN)*100\n",
    "print(f\"Sensitivity or TPR: {Sensitivity}%\")  \n",
    "print(f\"There is a {Sensitivity}% chance of detecting patients with an abnormality have an abnormality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is the sensitivity good enough for this scenario?\n",
    "\n",
    "\n",
    "### Specificity\n",
    "\n",
    "The next statistic is *specificity*, which is also known as the *true negative*. It measures the proportion of the actual negatives that are correctly identified.\n",
    "\n",
    "In this example, the specificity is *the probablity of detecting normal, for patients who are normal*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity or true negative rate\n",
    "Specificity  = float(TN)/(TN+FP)*100\n",
    "print(f\"Specificity or TNR: {Specificity}%\") \n",
    "print(f\"There is a {Specificity}% chance of detecting normal patients are normal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is this specificity too low, exactly right, or too high? What value  would you want to see here, given the scenario?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive and negative predictive values\n",
    "\n",
    "The *precision*, or *positive predictive value*, is the proportion of positive results.\n",
    "\n",
    "In this example, the positive predictive value is *the probability that subjects with a positive screening test truly have an abnormality*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision or positive predictive value\n",
    "Precision = float(TP)/(TP+FP)*100\n",
    "print(f\"Precision: {Precision}%\")  \n",
    "print(f\"You have an abnormality, and the probablity that is correct is {Precision}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *negative predictive value* is the proportion of negative results.\n",
    "\n",
    "In this example, the negative predictive value is *the probability that subjects with a negative screening test truly have an abnormality*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "NPV = float(TN)/(TN+FN)*100\n",
    "print(f\"Negative Predictive Value: {NPV}%\") \n",
    "print(f\"You don't have an abnormality, but there is a {NPV}% chance that is incorrect\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the impact of these values. If you were a patient, how worried should you be if the test for an abnormality was positive? On the opposite side, how reassured should you be if you tested negative?\n",
    "\n",
    "\n",
    "### False positive rate\n",
    "\n",
    "The *false positive rate (FPR)* is the probability that a false alarm will be raised, or that *a positive result will be given when the true value is negative*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fall out or false positive rate\n",
    "FPR = float(FP)/(FP+TN)*100\n",
    "print( f\"False Positive Rate: {FPR}%\") \n",
    "print( f\"There is a {FPR}% chance that this positive result is incorrect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False negative rate\n",
    "\n",
    "The *false negative rate* -- or *miss rate* -- is *the probability that a true positive will be missed by the test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False negative rate\n",
    "FNR = float(FN)/(TP+FN)*100\n",
    "print(f\"False Negative Rate: {FNR}%\") \n",
    "print(f\"There is a {FNR}% chance that this negative result is incorrect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False discovery rate\n",
    "\n",
    "In this example, the *false discovery rate* is *the probability of predicting an abnormality when the patient doesn't have one*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False discovery rate\n",
    "FDR = float(FP)/(TP+FP)*100\n",
    "print(f\"False Discovery Rate: {FDR}%\" )\n",
    "print(f\"You have an abnormality, but there is a {FDR}% chance this is incorrect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall accuracy\n",
    "\n",
    "How accuracte is your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy\n",
    "ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n",
    "print(f\"Accuracy: {ACC}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, you calculated the following metrics from your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n",
    "print(f\"Specificity or TNR: {Specificity}%\") \n",
    "print(f\"Precision: {Precision}%\")   \n",
    "print(f\"Negative Predictive Value: {NPV}%\")  \n",
    "print( f\"False Positive Rate: {FPR}%\") \n",
    "print(f\"False Negative Rate: {FNR}%\")  \n",
    "print(f\"False Discovery Rate: {FDR}%\" )\n",
    "print(f\"Accuracy: {ACC}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge task:** Record the previous values, then go back to step 1 and change the value used for the threshold. Values you should try are *.25* and *.75*. \n",
    "\n",
    "Did those threshold values make a difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Calculating the AUC-ROC Curve\n",
    "\n",
    "The scikit-learn library has functions that can help you compute the *area under the receiver operating characteristic curve (AUC-ROC)*.\n",
    "\n",
    "- The ROC is a probability curve.\n",
    "- The AUC tells you how well the model can distinguish between classes. \n",
    "\n",
    "The AUC can be calculated. As you will see in the next lab, it can be used to measure the performance of the model. \n",
    "\n",
    "In this example, the higher the AUC, the better the model is at distinguishing between abnormal and normal patients.\n",
    "\n",
    "Depending on the value you set for the threshold, the AUC can change. You can plot the AUC by using the probability instead of your converted class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test.iloc[:,0];\n",
    "print(\"Validation AUC\", roc_auc_score(test_labels, target_predicted) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the ROC curve is plotted with the TPR against the FPR, where the TPR is on the y-axis and the FPR is on the x-axis.\n",
    "\n",
    "scikit-learn has the **roc_curve** function to help generate those values to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, target_predicted)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    " \n",
    "# create the axis of thresholds (scores)\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='r')\n",
    "ax2.set_ylabel('Threshold',color='r')\n",
    "ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "ax2.set_xlim([fpr[0],fpr[-1]])\n",
    "\n",
    "print(plt.figure())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge task:** Update the previous code to use *target_predicted_binary* instead of *target_predicted*. How does that change the graph? Which is the most useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have completed this lab, and you can now end the lab by following the lab guide instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
